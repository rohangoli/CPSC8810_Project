kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /home/rgoli/.conda/envs/rapids-22.02/include/rmm/mr/device/cuda_memory_resource.hpp')"

distributed.worker - WARNING - Compute Failed
Function:  _transform_func
args:      (TfidfTransformer(), <cupyx.scipy.sparse.csr.csr_matrix object at 0x1535c1a06700>)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /home/rgoli/.conda/envs/rapids-22.02/include/rmm/mr/device/cuda_memory_resource.hpp')


(base) [rgoli@node0006 ~]$ nvidia-smi
Sat Apr 23 16:00:20 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.42.01    Driver Version: 470.42.01    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  Off  | 00000000:1A:00.0 Off |                    0 |
| N/A   33C    P0    54W / 300W |  16148MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-SXM2...  Off  | 00000000:1C:00.0 Off |                    0 |
| N/A   28C    P0    53W / 300W |  16095MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-SXM2...  Off  | 00000000:1D:00.0 Off |                    0 |
| N/A   31C    P0    53W / 300W |  16113MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-SXM2...  Off  | 00000000:1E:00.0 Off |                    0 |
| N/A   32C    P0    55W / 300W |  16147MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      4626      G   /usr/libexec/Xorg                  22MiB |
|    0   N/A  N/A   3637440      C   python                           1283MiB |
|    0   N/A  N/A   3637571      C   ...s/rapids-22.02/bin/python    14839MiB |
|    1   N/A  N/A      4626      G   /usr/libexec/Xorg                  22MiB |
|    1   N/A  N/A   3637580      C   ...s/rapids-22.02/bin/python    16069MiB |
|    2   N/A  N/A      4626      G   /usr/libexec/Xorg                  22MiB |
|    2   N/A  N/A   3637576      C   ...s/rapids-22.02/bin/python    16087MiB |
|    3   N/A  N/A      4626      G   /usr/libexec/Xorg                  22MiB |
|    3   N/A  N/A   3637582      C   ...s/rapids-22.02/bin/python    16121MiB |
+-----------------------------------------------------------------------------+
(base) [rgoli@node0006 ~]$ 
========================================================================================
(rapids-22.02) [rgoli@node0006 Project]$ python Rapids_Dask/tfidf_rapids_pipeline_v2.py -d data.tsv -f tsv
distributed.diskutils - INFO - Found stale lock file and directory '/home/rgoli/clemson/cpsc-8810-ece8930/Project/dask-worker-space/worker-0cgq120f', purging
distributed.diskutils - INFO - Found stale lock file and directory '/home/rgoli/clemson/cpsc-8810-ece8930/Project/dask-worker-space/worker-c3v00tdz', purging
distributed.diskutils - INFO - Found stale lock file and directory '/home/rgoli/clemson/cpsc-8810-ece8930/Project/dask-worker-space/worker-bnu47nvg', purging
distributed.diskutils - INFO - Found stale lock file and directory '/home/rgoli/clemson/cpsc-8810-ece8930/Project/dask-worker-space/worker-2k7hxqe9', purging
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Total Files: 30
Total Size: 50.2GB

distributed.worker - WARNING - Compute Failed
Function:  _transform_func
args:      (TfidfTransformer(), <cupyx.scipy.sparse.csr.csr_matrix object at 0x1521a0c2d6a0>)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /home/rgoli/.conda/envs/rapids-22.02/include/rmm/mr/device/cuda_memory_resource.hpp')"
========================================================================================
(rapids-22.02) [rgoli@node0006 Project]$ python Rapids_Dask/tfidf_rapids_pipeline_v2.py -d data.tsv -f tsv
distributed.diskutils - INFO - Found stale lock file and directory '/home/rgoli/clemson/cpsc-8810-ece8930/Project/dask-worker-space/worker-qca39c_8', purging
distributed.diskutils - INFO - Found stale lock file and directory '/home/rgoli/clemson/cpsc-8810-ece8930/Project/dask-worker-space/worker-ans47eti', purging
distributed.diskutils - INFO - Found stale lock file and directory '/home/rgoli/clemson/cpsc-8810-ece8930/Project/dask-worker-space/worker-wdknymzh', purging
distributed.diskutils - INFO - Found stale lock file and directory '/home/rgoli/clemson/cpsc-8810-ece8930/Project/dask-worker-space/worker-94jbfi20', purging
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Total Files: 20
Total Size: 35.2GB
(base) [rgoli@node0006 ~]$ nvidia-smi
Sat Apr 23 16:13:00 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.42.01    Driver Version: 470.42.01    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  Off  | 00000000:1A:00.0 Off |                    0 |
| N/A   35C    P0    65W / 300W |   4298MiB / 16160MiB |     30%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-SXM2...  Off  | 00000000:1C:00.0 Off |                    0 |
| N/A   29C    P0    62W / 300W |   2851MiB / 16160MiB |      1%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-SXM2...  Off  | 00000000:1D:00.0 Off |                    0 |
| N/A   32C    P0    63W / 300W |   3305MiB / 16160MiB |      1%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-SXM2...  Off  | 00000000:1E:00.0 Off |                    0 |
| N/A   34C    P0    66W / 300W |   3245MiB / 16160MiB |    100%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      4626      G   /usr/libexec/Xorg                  22MiB |
|    0   N/A  N/A   3639938      C   python                           1283MiB |
|    0   N/A  N/A   3640069      C   ...s/rapids-22.02/bin/python     2989MiB |
|    1   N/A  N/A      4626      G   /usr/libexec/Xorg                  22MiB |
|    1   N/A  N/A   3640074      C   ...s/rapids-22.02/bin/python     2825MiB |
|    2   N/A  N/A      4626      G   /usr/libexec/Xorg                  22MiB |
|    2   N/A  N/A   3640080      C   ...s/rapids-22.02/bin/python     3279MiB |
|    3   N/A  N/A      4626      G   /usr/libexec/Xorg                  22MiB |
|    3   N/A  N/A   3640077      C   ...s/rapids-22.02/bin/python     3219MiB |
+------------------------------------------------------------------------------+
(base) [rgoli@node0006 ~]$ nvidia-smi
Sat Apr 23 16:13:22 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.42.01    Driver Version: 470.42.01    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  Off  | 00000000:1A:00.0 Off |                    0 |
| N/A   34C    P0    66W / 300W |   4864MiB / 16160MiB |      3%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-SXM2...  Off  | 00000000:1C:00.0 Off |                    0 |
| N/A   31C    P0   130W / 300W |   3789MiB / 16160MiB |     92%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-SXM2...  Off  | 00000000:1D:00.0 Off |                    0 |
| N/A   33C    P0   104W / 300W |   3937MiB / 16160MiB |     94%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-SXM2...  Off  | 00000000:1E:00.0 Off |                    0 |
| N/A   33C    P0    65W / 300W |   3277MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      4626      G   /usr/libexec/Xorg                  22MiB |
|    0   N/A  N/A   3639938      C   python                           1283MiB |
|    0   N/A  N/A   3640069      C   ...s/rapids-22.02/bin/python     3555MiB |
|    1   N/A  N/A      4626      G   /usr/libexec/Xorg                  22MiB |
|    1   N/A  N/A   3640074      C   ...s/rapids-22.02/bin/python     3679MiB |
|    2   N/A  N/A      4626      G   /usr/libexec/Xorg                  22MiB |
|    2   N/A  N/A   3640080      C   ...s/rapids-22.02/bin/python     3911MiB |
|    3   N/A  N/A      4626      G   /usr/libexec/Xorg                  22MiB |
|    3   N/A  N/A   3640077      C   ...s/rapids-22.02/bin/python     3251MiB |
+-----------------------------------------------------------------------------+
(base) [rgoli@node0006 ~]$ nvidia-smi
Sat Apr 23 16:13:26 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.42.01    Driver Version: 470.42.01    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  Off  | 00000000:1A:00.0 Off |                    0 |
| N/A   35C    P0   113W / 300W |   4770MiB / 16160MiB |     46%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-SXM2...  Off  | 00000000:1C:00.0 Off |                    0 |
| N/A   29C    P0    62W / 300W |   3499MiB / 16160MiB |      1%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-SXM2...  Off  | 00000000:1D:00.0 Off |                    0 |
| N/A   32C    P0    65W / 300W |   3629MiB / 16160MiB |      1%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-SXM2...  Off  | 00000000:1E:00.0 Off |                    0 |
| N/A   33C    P0    65W / 300W |   3345MiB / 16160MiB |      1%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      4626      G   /usr/libexec/Xorg                  22MiB |
|    0   N/A  N/A   3639938      C   python                           1283MiB |
|    0   N/A  N/A   3640069      C   ...s/rapids-22.02/bin/python     3549MiB |
|    1   N/A  N/A      4626      G   /usr/libexec/Xorg                  22MiB |
|    1   N/A  N/A   3640074      C   ...s/rapids-22.02/bin/python     3473MiB |
|    2   N/A  N/A      4626      G   /usr/libexec/Xorg                  22MiB |
|    2   N/A  N/A   3640080      C   ...s/rapids-22.02/bin/python     3603MiB |
|    3   N/A  N/A      4626      G   /usr/libexec/Xorg                  22MiB |
|    3   N/A  N/A   3640077      C   ...s/rapids-22.02/bin/python     3319MiB |
+-----------------------------------------------------------------------------+
(rapids-22.02) [rgoli@node0006 Project]$ python Rapids_Dask/tfidf_rapids_pipeline_v2.py -d data.tsv -f tsv
distributed.diskutils - INFO - Found stale lock file and directory '/home/rgoli/clemson/cpsc-8810-ece8930/Project/dask-worker-space/worker-qca39c_8', purging
distributed.diskutils - INFO - Found stale lock file and directory '/home/rgoli/clemson/cpsc-8810-ece8930/Project/dask-worker-space/worker-ans47eti', purging
distributed.diskutils - INFO - Found stale lock file and directory '/home/rgoli/clemson/cpsc-8810-ece8930/Project/dask-worker-space/worker-wdknymzh', purging
distributed.diskutils - INFO - Found stale lock file and directory '/home/rgoli/clemson/cpsc-8810-ece8930/Project/dask-worker-space/worker-94jbfi20', purging
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Total Files: 20
Total Size: 35.2GB
Total Time: 2.21e+02 seconds ~ 221 seconds ~ 3.63 minutes
(rapids-22.02) [rgoli@node0006 Project]$
(rapids-22.02) [rgoli@node0006 Project]$ python Rapids_Dask/tfidf_rapids_pipeline_v2.py -d data.tsv -f tsv
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Total Files: 25
Total Size: 42.3GB
Total Time: 2.54e+02 seconds ~ 254 seconds ~ 4.23 minutes
(rapids-22.02) [rgoli@node0006 Project]$ 
(rapids-22.02) [rgoli@node0006 Project]$ python Rapids_Dask/tfidf_rapids_pipeline_v2.py -d data.tsv -f tsv
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Total Files: 30
Total Size: 50.2GB
    frames = [dask_deserialize_cuda_buffer(header, frames)]
  File "/home/rgoli/.conda/envs/rapids-22.02/lib/python3.8/site-packages/distributed/protocol/rmm.py", line 44, in dask_deserialize_rmm_device_buffer
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "rmm/_lib/device_buffer.pyx", line 90, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /home/rgoli/.conda/envs/rapids-22.02/include/rmm/mr/device/cuda_memory_resource.hpp
^Z
----
(rapids-22.02) [rgoli@node0006 Project]$ python Rapids_Dask/tfidf_rapids_pipeline_v2.py -d data.tsv -f tsv
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Total Files: 10
Total Size: 15.8GB
Total Time: 1.11e+02 seconds ~ 111 seconds ~ 2 minutes
(rapids-22.02) [rgoli@node0006 Project]$ python Rapids_Dask/tfidf_rapids_pipeline_v2.py -d data.tsv -f tsv
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Total Files: 27
Total Size: 46.8GB

File "rmm/_lib/device_buffer.pyx", line 90, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /home/rgoli/.conda/envs/rapids-22.02/include/rmm/mr/device/cuda_memory_resource.hpp

(rapids-22.02) [rgoli@node0006 Project]$ python Rapids_Dask/tfidf_rapids_pipeline_v2.py -d data.tsv -f tsv
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Total Files: 5
Total Size: 8.0GB
Total Time: 59.9 seconds

=======================================
(rapids-22.02) [rgoli@node0006 Project]$ python Rapids_Dask/tfidf_rapids_pipeline_v2.py -d data.tsv -f tsv
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Total Files: 26
Total Size: 45.7GB
distributed.worker - WARNING - Compute Failed
Function:  _transform_func
args:      (TfidfTransformer(), <cupyx.scipy.sparse.csr.csr_matrix object at 0x14ee5c34c370>)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /home/rgoli/.conda/envs/rapids-22.02/include/rmm/mr/device/cuda_memory_resource.hpp')"

distributed.worker - WARNING - Compute Failed
Function:  _transform_func
args:      (TfidfTransformer(), <cupyx.scipy.sparse.csr.csr_matrix object at 0x14ee55f247c0>)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /home/rgoli/.conda/envs/rapids-22.02/include/rmm/mr/device/cuda_memory_resource.hpp')"

distributed.worker - WARNING - Compute Failed
Function:  _transform_func
args:      (TfidfTransformer(), <cupyx.scipy.sparse.csr.csr_matrix object at 0x14ee55f24970>)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /home/rgoli/.conda/envs/rapids-22.02/include/rmm/mr/device/cuda_memory_resource.hpp')"

distributed.worker - WARNING - Compute Failed
Function:  _transform_func
args:      (TfidfTransformer(), <cupyx.scipy.sparse.csr.csr_matrix object at 0x14ee55fba6a0>)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /home/rgoli/.conda/envs/rapids-22.02/include/rmm/mr/device/cuda_memory_resource.hpp')"

distributed.worker - WARNING - Compute Failed
Function:  _transform_func
args:      (TfidfTransformer(), <cupyx.scipy.sparse.csr.csr_matrix object at 0x14ee5c34ccd0>)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /home/rgoli/.conda/envs/rapids-22.02/include/rmm/mr/device/cuda_memory_resource.hpp')"

distributed.worker - WARNING - Compute Failed
Function:  _transform_func
args:      (TfidfTransformer(), <cupyx.scipy.sparse.csr.csr_matrix object at 0x14ee55f24ee0>)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /home/rgoli/.conda/envs/rapids-22.02/include/rmm/mr/device/cuda_memory_resource.hpp')"

distributed.worker - WARNING - Compute Failed
Function:  _transform_func
args:      (TfidfTransformer(), <cupyx.scipy.sparse.csr.csr_matrix object at 0x14ee5c0e8eb0>)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /home/rgoli/.conda/envs/rapids-22.02/include/rmm/mr/device/cuda_memory_resource.hpp')"

distributed.worker - WARNING - Compute Failed
Function:  _transform_func
args:      (TfidfTransformer(), <cupyx.scipy.sparse.csr.csr_matrix object at 0x14ee55fba7c0>)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /home/rgoli/.conda/envs/rapids-22.02/include/rmm/mr/device/cuda_memory_resource.hpp')"

Traceback (most recent call last):
  File "Rapids_Dask/tfidf_rapids_pipeline_v2.py", line 107, in <module>
    result = full_pipeline_tsv(client,FILES[:fc])
  File "Rapids_Dask/tfidf_rapids_pipeline_v2.py", line 77, in full_pipeline_tsv
    result = tfidf_transformer(result, client)
  File "Rapids_Dask/tfidf_rapids_pipeline_v2.py", line 59, in tfidf_transformer
    result.compute_chunk_sizes()
  File "/home/rgoli/.conda/envs/rapids-22.02/lib/python3.8/site-packages/dask/array/core.py", line 1389, in compute_chunk_sizes
    tuple(int(chunk) for chunk in chunks) for chunks in compute(tuple(c))[0]
  File "/home/rgoli/.conda/envs/rapids-22.02/lib/python3.8/site-packages/dask/base.py", line 571, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/home/rgoli/.conda/envs/rapids-22.02/lib/python3.8/site-packages/distributed/client.py", line 2746, in get
    results = self.gather(packed, asynchronous=asynchronous, direct=direct)
  File "/home/rgoli/.conda/envs/rapids-22.02/lib/python3.8/site-packages/distributed/client.py", line 1946, in gather
    return self.sync(
  File "/home/rgoli/.conda/envs/rapids-22.02/lib/python3.8/site-packages/distributed/utils.py", line 310, in sync
    return sync(
  File "/home/rgoli/.conda/envs/rapids-22.02/lib/python3.8/site-packages/distributed/utils.py", line 364, in sync
    raise exc.with_traceback(tb)
  File "/home/rgoli/.conda/envs/rapids-22.02/lib/python3.8/site-packages/distributed/utils.py", line 349, in f
    result[0] = yield future
  File "/home/rgoli/.conda/envs/rapids-22.02/lib/python3.8/site-packages/tornado/gen.py", line 762, in run
    value = future.result()
  File "/home/rgoli/.conda/envs/rapids-22.02/lib/python3.8/site-packages/distributed/client.py", line 1811, in _gather
    raise exception.with_traceback(traceback)
  File "/home/rgoli/.conda/envs/rapids-22.02/lib/python3.8/site-packages/cuml/dask/common/base.py", line 432, in _transform_func
    return model.transform(data, **kwargs)
  File "/home/rgoli/.conda/envs/rapids-22.02/lib/python3.8/site-packages/cuml/internals/api_decorators.py", line 415, in inner
    return func(*args, **kwargs)
  File "/home/rgoli/.conda/envs/rapids-22.02/lib/python3.8/site-packages/cuml/feature_extraction/_tfidf.py", line 206, in transform
    X = X.copy()
  File "/home/rgoli/.conda/envs/rapids-22.02/lib/python3.8/site-packages/cupyx/scipy/sparse/data.py", line 60, in copy
    return self._with_data(self.data.copy(), copy=True)
  File "/home/rgoli/.conda/envs/rapids-22.02/lib/python3.8/site-packages/cupyx/scipy/sparse/compressed.py", line 302, in _with_data
    (data, self.indices.copy(), self.indptr.copy()),
  File "cupy/_core/core.pyx", line 475, in cupy._core.core.ndarray.copy
  File "cupy/_core/core.pyx", line 501, in cupy._core.core.ndarray.copy
  File "cupy/_core/core.pyx", line 460, in cupy._core.core.ndarray.astype
  File "cupy/_core/core.pyx", line 167, in cupy._core.core.ndarray.__init__
  File "cupy/cuda/memory.pyx", line 718, in cupy.cuda.memory.alloc
  File "/home/rgoli/.conda/envs/rapids-22.02/lib/python3.8/site-packages/rmm/rmm.py", line 212, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "rmm/_lib/device_buffer.pyx", line 88, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /home/rgoli/.conda/envs/rapids-22.02/include/rmm/mr/device/cuda_memory_resource.hpp
(rapids-22.02) [rgoli@node0006 Project]$ 